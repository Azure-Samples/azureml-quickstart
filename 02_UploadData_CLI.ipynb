{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Azure Workspace Data asset from local file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import a Data assets into the Azure ML Workspace using CLI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import local data into the Azure ML Platform workspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dependencies/dataimport.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json\n",
    "name: credit_cards\n",
    "description: Data asset created from local file.\n",
    "type: uri_file\n",
    "path: ../data/default_of_credit_card_clients.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml data create --file dependencies/dataimport.yml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read [Access data from Azure cloud storage during interactive development](how-to-access-data-interactive.md) to learn more about data access in a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Parquet version of the Data asset\n",
    "\n",
    "Create a new version of the data asset and store in Parquet file format\n",
    "\n",
    "You might have noticed that the data needs a little light cleaning, to make it fit to train a machine learning model. It has:\n",
    "\n",
    "* two headers\n",
    "* a client ID column; we wouldn't use this feature in Machine Learning\n",
    "* spaces in the response variable name\n",
    "\n",
    "Also, compared to the CSV format, the Parquet file format becomes a better way to store this data. Parquet offers compression, and it maintains schema. Therefore, to clean the data and store it in Parquet, use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a: Install data wrangling libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in data again, this time using the 2nd row as the header\n",
    "df = pd.read_csv(\"data/default_of_credit_card_clients.csv\", header=1)\n",
    "# rename column\n",
    "df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "# remove ID column\n",
    "df.drop(\"ID\", axis=1, inplace=True)\n",
    "\n",
    "# write file to filesystem\n",
    "df.to_parquet(\"./data/cleaned-credit-card.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the structure of the data in the original **default_of_credit_card_clients.csv** file .CSV file downloaded in an earlier step. The uploaded data contains 23 explanatory variables and 1 response variable, as shown here:\n",
    "\n",
    "|Column Name(s) | Variable Type  |Description  |\n",
    "|---------|---------|---------|\n",
    "|X1     |   Explanatory      |    Amount of the given credit (NT dollar): it includes both the individual consumer credit and their family (supplementary) credit.    |\n",
    "|X2     |   Explanatory      |   Gender (1 = male; 2 = female).      |\n",
    "|X3     |   Explanatory      |   Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).      |\n",
    "|X4     |   Explanatory      |    Marital status (1 = married; 2 = single; 3 = others).     |\n",
    "|X5     |   Explanatory      |    Age (years).     |\n",
    "|X6-X11     | Explanatory        |  History of past payment. We tracked the past monthly payment records (from April to September  2005). -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.      |\n",
    "|X12-17     | Explanatory        |  Amount of bill statement (NT dollar) from April to September  2005.      |\n",
    "|X18-23     | Explanatory        |  Amount of previous payment (NT dollar) from April to September  2005.      |\n",
    "|Y     | Response        |    Default payment (Yes = 1, No = 0)     |\n",
    "\n",
    "Next, create a new _version_ of the data asset (the data automatically uploads to cloud storage):\n",
    "\n",
    "> [!NOTE]\n",
    ">\n",
    "> This Python code cell sets **name** and **version** values for the data asset it creates. As a result, the code in this cell will fail if executed more than once, without a change to these values. Fixed **name** and **version** values offer a way to pass values that work for specific situations, without concern for auto-generated or randomly-generated values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Import local data into the Azure ML Platform workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dependencies/dataimport_parquet.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json\n",
    "name: credit_cards_parquet\n",
    "description: Data asset created from local file.\n",
    "type: uri_file\n",
    "path: ../data/cleaned-credit-card.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml data create --file dependencies/dataimport_parquet.yml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
