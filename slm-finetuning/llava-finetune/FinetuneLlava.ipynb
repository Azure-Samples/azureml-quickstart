{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552564642
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552564802
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall datasets -y"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.19.1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade --force-reinstall Pillow"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552634066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep datasets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Multimodal-Fatima/OK-VQA_train\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552658706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import uuid"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552685160
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check PIL import\n",
        "import PIL.Image"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552687757
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessing functions\n",
        "def process_and_save(dataset, output_folder, subset_name):\n",
        "    # Define image subfolder within output folder\n",
        "    subset_folder = os.path.join(output_folder, subset_name)\n",
        "    image_subfolder = os.path.join(output_folder, 'images')\n",
        "\n",
        "    if not os.path.exists(image_subfolder):\n",
        "        os.makedirs(image_subfolder)\n",
        "\n",
        "    if not os.path.exists(subset_folder):\n",
        "        os.makedirs(subset_folder)\n",
        "\n",
        "    # Initialize list to hold all JSON data\n",
        "    json_data_list = []\n",
        "\n",
        "    # Process and save images and labels\n",
        "    for item in dataset:\n",
        "        # Load image if it's a URL or a file path\n",
        "        if isinstance(item['image'], str):\n",
        "            response = requests.get(item['image'])\n",
        "            image = Image.open(BytesIO(response.content))\n",
        "        else:\n",
        "            image = item['image']  # Assuming it's a PIL.Image object\n",
        "\n",
        "        # Create a unique ID for each image\n",
        "        unique_id = str(uuid.uuid4())\n",
        "\n",
        "        # Define image path\n",
        "        image_path = os.path.join(image_subfolder, f\"{unique_id}.jpg\")\n",
        "\n",
        "        # Save image\n",
        "        image.save(image_path)\n",
        "\n",
        "        # Remove duplicates and format answers\n",
        "        answers = item['answers']\n",
        "        unique_answers = list(set(answers))\n",
        "        formatted_answers = \", \".join(unique_answers)\n",
        "\n",
        "        # Structure for LLaVA JSON\n",
        "        json_data = {\n",
        "            \"id\": unique_id,\n",
        "            \"image\": f\"{unique_id}.jpg\",\n",
        "            \"conversations\": [\n",
        "                {\n",
        "                    \"from\": \"human\",\n",
        "                    \"value\": item['question']\n",
        "                },\n",
        "                {\n",
        "                    \"from\": \"gpt\",\n",
        "                    \"value\": formatted_answers\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Append to list\n",
        "        json_data_list.append(json_data)\n",
        "\n",
        "    # Save the JSON data list to a file\n",
        "    json_output_path = os.path.join(output_folder, subset_name, 'dataset.json')\n",
        "    with open(json_output_path, 'w') as json_file:\n",
        "        json.dump(json_data_list, json_file, indent=4)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552693192
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset(dataset_name, output_folder, class_name, subset_name, val_samples=None):\n",
        "    # Load the dataset from Hugging Face\n",
        "    dataset = load_dataset(dataset_name, split=subset_name)\n",
        "    \n",
        "    # Filter for images with the specified class in 'question_type'\n",
        "    filtered_dataset = [item for item in dataset if item['question_type'] == class_name]\n",
        "\n",
        "    # Determine the split for training and validation\n",
        "    if val_samples is not None and subset_name == 'train':\n",
        "        train_dataset = filtered_dataset[val_samples:]\n",
        "        val_dataset = filtered_dataset[:val_samples]\n",
        "    else:\n",
        "        train_dataset = filtered_dataset\n",
        "        val_dataset = []\n",
        "\n",
        "    # Process and save the datasets\n",
        "    for subset, data in [('train', train_dataset), ('validation', val_dataset)]:\n",
        "        if data:\n",
        "            process_and_save(data, output_folder, subset)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552696972
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = 'dataset'\n",
        "class_name = 'other'\n",
        "val_samples = 300\n",
        "save_dataset('Multimodal-Fatima/OK-VQA_train', output_folder, class_name, 'train', val_samples)\n",
        "save_dataset('Multimodal-Fatima/OK-VQA_test', output_folder, class_name, 'test')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716552888571
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "!cd LLaVA && pip install --upgrade pip && pip install -e ."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaVA && pip install -e \".[train]\"\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# \n",
        "wandb.login()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716553408225
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install flash-attn --no-build-isolation"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!deepspeed LLaVA/llava/train/train_mem.py \\\n",
        "    --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 \\\n",
        "    --deepspeed LLaVA/scripts/zero3.json \\\n",
        "    --model_name_or_path liuhaotian/llava-v1.5-13b \\\n",
        "    --version v1 \\\n",
        "    --data_path ./dataset/train/dataset.json \\\n",
        "    --image_folder ./dataset/images \\\n",
        "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_im_start_end False \\\n",
        "    --mm_use_im_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 False \\\n",
        "    --output_dir ./checkpoints/llava-v1.5-13b-task-lora \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 False \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to wandb"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1716554662627
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}