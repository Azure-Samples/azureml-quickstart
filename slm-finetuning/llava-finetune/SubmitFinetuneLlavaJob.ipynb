{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile finetune_llava_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: ./src\n",
    "\n",
    "command: >- \n",
    "  echo \"./finetune_llava.sh ${{inputs.data_dir}} ${{outputs.out_dir}}\"; sleep 60000\n",
    "inputs:\n",
    "  data_dir: \n",
    "    type: uri_folder\n",
    "    mode: ro_mount\n",
    "    #path: azureml:Multimodal-Fatima_OK@latest\n",
    "outputs:\n",
    "  out_dir: \n",
    "    type: uri_folder\n",
    "    mode: upload\n",
    "environment: azureml:llava_finetuning@latest\n",
    "resources:\n",
    "  instance_count: 1\n",
    "distribution:\n",
    "  type: pytorch \n",
    "  process_count_per_instance: 4\n",
    "services:\n",
    "    my_vs_code:\n",
    "      type: vs_code\n",
    "      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "    my_jupyter_lab:\n",
    "      type: jupyter_lab\n",
    "      nodes: all\n",
    "#compute: azureml:fine-tune-cluster\n",
    "compute: azureml:a100-low-priority\n",
    "display_name: finetune_llava_job\n",
    "name: finetune_llava_job\n",
    "experiment_name: finetune_llava\n",
    "description: Finetune LlaVa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml job create -f ./finetune_llava_job.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml component create -f ./finetune_llava_job.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Finetuned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting merge_finetuned_llava_job.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile merge_finetuned_llava_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "command: >- \n",
    "  python /LLaVA/scripts/merge_lora_weights.py --model-path ${{inputs.checkpoints_home}}/checkpoints/llava-v1.5-13b-task-lora --model-base liuhaotian/llava-v1.5-13b --save-model-path ${{outputs.llava_out_dir}}\n",
    "inputs:\n",
    "  checkpoints_home: \n",
    "    type: uri_folder\n",
    "    #mode: ro_mount\n",
    "    path: azureml:azureml_bright_office_tsywj86mp0_output_data_out_dir:1\n",
    "outputs:\n",
    "  llava_out_dir: \n",
    "    type: custom_model\n",
    "    mode: upload\n",
    "environment: azureml:llava_finetuning:16\n",
    "resources:\n",
    "  instance_count: 1\n",
    "distribution:\n",
    "  type: pytorch \n",
    "  process_count_per_instance: 4\n",
    "services:\n",
    "    my_vs_code:\n",
    "      type: vs_code\n",
    "      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "    my_jupyter_lab:\n",
    "      type: jupyter_lab\n",
    "      nodes: all\n",
    "compute: azureml:antonslutsky1\n",
    "#compute: azureml:fine-tune-cluster\n",
    "#compute: azureml:a100-low-priority\n",
    "display_name: merge_finetuned_llava_job\n",
    "#name: merge_finetuned_llava_job\n",
    "experiment_name: finetune_llava\n",
    "description: Save finetuned LlaVa weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"command\": \"python /LLaVA/scripts/merge_lora_weights.py --model-path ${{inputs.checkpoints_home}}/checkpoints/llava-v1.5-13b-task-lora --model-base liuhaotian/llava-v1.5-13b --save-model-path ${{outputs.llava_out_dir}}\",\n",
      "  \"compute\": \"azureml:antonslutsky1\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2024-05-31T13:30:03.398256+00:00\",\n",
      "    \"created_by\": \"Anton Slutsky\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"Save finetuned LlaVa weights.\",\n",
      "  \"display_name\": \"merge_finetuned_llava_job\",\n",
      "  \"distribution\": {\n",
      "    \"process_count_per_instance\": 4,\n",
      "    \"type\": \"pytorch\"\n",
      "  },\n",
      "  \"environment\": \"azureml:llava_finetuning:16\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"finetune_llava\",\n",
      "  \"id\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/jobs/tough_plow_b5dv514mdv\",\n",
      "  \"inputs\": {\n",
      "    \"checkpoints_home\": {\n",
      "      \"mode\": \"ro_mount\",\n",
      "      \"path\": \"azureml:azureml_bright_office_tsywj86mp0_output_data_out_dir:1\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"tough_plow_b5dv514mdv\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.tough_plow_b5dv514mdv\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    },\n",
      "    \"llava_out_dir\": {\n",
      "      \"mode\": \"upload\",\n",
      "      \"type\": \"custom_model\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"_azureml.ClusterName\": \"antonslutsky1\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlcdsi\",\n",
      "    \"azureml.git.dirty\": \"True\",\n",
      "    \"mlflow.source.git.branch\": \"slm_finetuning/llava\",\n",
      "    \"mlflow.source.git.commit\": \"f9e394bcff9632aa62163145701c34b8f908a034\",\n",
      "    \"mlflow.source.git.repoURL\": \"https://github.com/Azure-Samples/azureml-quickstart.git\"\n",
      "  },\n",
      "  \"resourceGroup\": \"antonslutsky-rg\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 1,\n",
      "    \"properties\": {},\n",
      "    \"shm_size\": \"2g\"\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/tough_plow_b5dv514mdv?wsid=/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/workspaces/gpu-workspace&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\",\n",
      "      \"type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://northeurope.api.azureml.ms/mlflow/v1.0/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace?\",\n",
      "      \"type\": \"Tracking\"\n",
      "    },\n",
      "    \"my_jupyter_lab\": {\n",
      "      \"properties\": {},\n",
      "      \"type\": \"jupyter_lab\"\n",
      "    },\n",
      "    \"my_vs_code\": {\n",
      "      \"properties\": {},\n",
      "      \"type\": \"vs_code\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "!az ml job create -f ./merge_finetuned_llava_job.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml component create -f ./merge_finetuned_llava_job.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile apply_finetuned_llava_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "command: >- \n",
    "  echo \"Model Home: ${{inputs.llava_model_home}} Output Dir: ${{outputs.out_dir}}\"; sleep 70000\n",
    "inputs:\n",
    "  llava_model_home: \n",
    "    type: uri_folder\n",
    "    #mode: ro_mount\n",
    "    path: azureml:azureml_tough_cherry_s5gzbchvct_output_data_out_dir:1\n",
    "outputs:\n",
    "  out_dir: \n",
    "    type: uri_folder\n",
    "    mode: upload\n",
    "environment: azureml:llava_finetuning@latest\n",
    "resources:\n",
    "  instance_count: 1\n",
    "distribution:\n",
    "  type: pytorch \n",
    "  process_count_per_instance: 4\n",
    "services:\n",
    "    my_vs_code:\n",
    "      type: vs_code\n",
    "      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "    my_jupyter_lab:\n",
    "      type: jupyter_lab\n",
    "      nodes: all\n",
    "compute: azureml:fine-tune-cluster\n",
    "#compute: azureml:a100-low-priority\n",
    "display_name: apply_finetuned_llava_job\n",
    "experiment_name: finetune_llava\n",
    "#name: apply_finetuned_llava_job\n",
    "description: Apply finetuned LlaVa weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml job create -f ./apply_finetuned_llava_job.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml component create -f ./apply_finetuned_llava_job.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
