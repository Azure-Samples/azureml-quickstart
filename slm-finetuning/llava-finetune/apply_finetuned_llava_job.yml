$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
command: >- 
  echo "Model Home: ${{inputs.llava_model_home}} Output Dir: ${{outputs.out_dir}}"; sleep 70000
inputs:
  llava_model_home: 
    type: uri_folder
    #mode: ro_mount
    path: azureml:azureml_tough_cherry_s5gzbchvct_output_data_out_dir:1
outputs:
  out_dir: 
    type: uri_folder
    mode: upload
environment: azureml:llava_finetuning@latest
resources:
  instance_count: 1
distribution:
  type: pytorch 
  process_count_per_instance: 4
services:
    my_vs_code:
      type: vs_code
      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are "all", or compute node index (for ex. "0", "1" etc.)
    my_jupyter_lab:
      type: jupyter_lab
      nodes: all
compute: azureml:fine-tune-cluster
#compute: azureml:a100-low-priority
display_name: apply_finetuned_llava_job
experiment_name: finetune_llava
#name: apply_finetuned_llava_job
description: Apply finetuned LlaVa weights.
