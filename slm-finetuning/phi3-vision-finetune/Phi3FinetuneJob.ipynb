{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile finetune_phi3_job.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: ./src\n",
    "\n",
    "command: >- \n",
    "  echo \"python finetune_phi3.py ${{inputs.data_dir}} ${{outputs.out_dir}}\"; sleep 60000\n",
    "inputs:\n",
    "  data_dir: \n",
    "    type: uri_folder\n",
    "    #mode: ro_mount\n",
    "    #path: azureml:burbery_data@latest\n",
    "    path: azureml:Sujet-Finance-Vision-10k@latest\n",
    "outputs:\n",
    "  out_dir: \n",
    "    type: custom_model\n",
    "    mode: upload\n",
    "environment: azureml:llava_finetuning:16\n",
    "environment_variables:\n",
    "    WANDB_MODE: disabled\n",
    "resources:\n",
    "  instance_count: 1\n",
    "distribution:\n",
    "  type: pytorch \n",
    "  process_count_per_instance: 1\n",
    "services:\n",
    "    my_vs_code:\n",
    "      type: vs_code\n",
    "      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "    my_jupyter_lab:\n",
    "      type: jupyter_lab\n",
    "      nodes: all\n",
    "#compute: azureml:fine-tune-cluster\n",
    "compute: azureml:a100-low-priority\n",
    "display_name: finetune_phi3_vision_job_5\n",
    "#name: finetune_phi3_vision_job\n",
    "experiment_name: finetune_phi3_vision\n",
    "description: Finetune Phi3 Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml job create -f finetune_phi3_job.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile endpoint_phi3_env_jo.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "command: >- \n",
    "  echo \"Model Dir: ${{inputs.model_dir}}\"; sleep 6000\n",
    "inputs:\n",
    "  model_dir: \n",
    "    type: custom_model\n",
    "    path: azureml:finetuned_phi3_vision@latest\n",
    "environment: azureml:llava_finetuning_inference:2\n",
    "environment_variables:\n",
    "    WANDB_MODE: disabled\n",
    "resources:\n",
    "  instance_count: 1\n",
    "distribution:\n",
    "  type: pytorch \n",
    "  process_count_per_instance: 1\n",
    "services:\n",
    "    my_vs_code:\n",
    "      type: vs_code\n",
    "      nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n",
    "    my_jupyter_lab:\n",
    "      type: jupyter_lab\n",
    "      nodes: all\n",
    "compute: azureml:fine-tune-cluster\n",
    "#compute: azureml:a100-low-priority\n",
    "display_name: endpoint_phi3_env_job\n",
    "#name: endpoint_phi3_env_job\n",
    "experiment_name: finetune_phi3_vision\n",
    "description: Endpoint Phi3 Vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml job create -f endpoint_phi3_env_jo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./endpoint/endpoint.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineEndpoint.schema.json\n",
    "name: finetunedPhi3Endpoint\n",
    "auth_mode: key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"auth_mode\": \"key\",\n",
      "  \"id\": \"/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/onlineEndpoints/finetunedphi3endpoint\",\n",
      "  \"identity\": {\n",
      "    \"principal_id\": \"c0258f71-08d2-4e8c-aa35-dbdb2f483ced\",\n",
      "    \"tenant_id\": \"16b3c013-d300-468d-ac64-7eda0820b6d3\",\n",
      "    \"type\": \"system_assigned\"\n",
      "  },\n",
      "  \"kind\": \"Managed\",\n",
      "  \"location\": \"northeurope\",\n",
      "  \"mirror_traffic\": {},\n",
      "  \"name\": \"finetunedphi3endpoint\",\n",
      "  \"openapi_uri\": \"https://finetunedphi3endpoint.northeurope.inference.ml.azure.com/swagger.json\",\n",
      "  \"properties\": {\n",
      "    \"AzureAsyncOperationUri\": \"https://management.azure.com/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/providers/Microsoft.MachineLearningServices/locations/northeurope/mfeOperationsStatus/oeidp:23317781-110c-4faf-9763-19f2fd34b6cf:d2b3ec37-40db-43d3-93b6-a4bc75ffe32b?api-version=2022-02-01-preview\",\n",
      "    \"azureml.onlineendpointid\": \"/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourcegroups/antonslutsky-rg/providers/microsoft.machinelearningservices/workspaces/gpu-workspace/onlineendpoints/finetunedphi3endpoint\"\n",
      "  },\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"public_network_access\": \"enabled\",\n",
      "  \"resourceGroup\": \"antonslutsky-rg\",\n",
      "  \"scoring_uri\": \"https://finetunedphi3endpoint.northeurope.inference.ml.azure.com/score\",\n",
      "  \"tags\": {},\n",
      "  \"traffic\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!az ml online-endpoint create --file ./endpoint/endpoint.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./endpoint/deployment.yaml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json\n",
    "name: blue\n",
    "endpoint_name: finetunedPhi3Endpoint\n",
    "model: azureml:finetuned_phi3_vision:1\n",
    "code_configuration:\n",
    "  code: .\n",
    "  scoring_script: score.py\n",
    "environment: azureml:llava_finetuning_inference:2\n",
    "instance_type: Standard_NC12s_v3\n",
    "instance_count: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................{\n",
      "  \"app_insights_enabled\": false,\n",
      "  \"code_configuration\": {\n",
      "    \"code\": \"/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/codes/ffd4e7ed-77bc-4a35-a524-cd57d9aee2a3/versions/1\",\n",
      "    \"scoring_script\": \"score.py\"\n",
      "  },\n",
      "  \"egress_public_network_access\": \"enabled\",\n",
      "  \"endpoint_name\": \"finetunedphi3endpoint\",\n",
      "  \"environment\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/environments/llava_finetuning_inference/versions/2\",\n",
      "  \"environment_variables\": {\n",
      "    \"AML_APP_ROOT\": \"/var/azureml-app/endpoint\",\n",
      "    \"AZUREML_ENTRY_SCRIPT\": \"score.py\",\n",
      "    \"AZUREML_MODEL_DIR\": \"/var/azureml-app/azureml-models/finetuned_phi3_vision/1\"\n",
      "  },\n",
      "  \"id\": \"/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/onlineEndpoints/finetunedphi3endpoint/deployments/blue\",\n",
      "  \"instance_count\": 1,\n",
      "  \"instance_type\": \"Standard_NC12s_v3\",\n",
      "  \"liveness_probe\": {\n",
      "    \"failure_threshold\": 30,\n",
      "    \"initial_delay\": 10,\n",
      "    \"period\": 10,\n",
      "    \"success_threshold\": 1,\n",
      "    \"timeout\": 2\n",
      "  },\n",
      "  \"model\": \"azureml:/subscriptions/781b03e7-6eb7-4506-bab8-cf3a0d89b1d4/resourceGroups/antonslutsky-rg/providers/Microsoft.MachineLearningServices/workspaces/gpu-workspace/models/finetuned_phi3_vision/versions/1\",\n",
      "  \"name\": \"blue\",\n",
      "  \"properties\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"readiness_probe\": {\n",
      "    \"failure_threshold\": 30,\n",
      "    \"initial_delay\": 10,\n",
      "    \"period\": 10,\n",
      "    \"success_threshold\": 1,\n",
      "    \"timeout\": 2\n",
      "  },\n",
      "  \"request_settings\": {\n",
      "    \"max_concurrent_requests_per_instance\": 1,\n",
      "    \"request_timeout_ms\": 5000\n",
      "  },\n",
      "  \"resourceGroup\": \"antonslutsky-rg\",\n",
      "  \"scale_settings\": {\n",
      "    \"type\": \"default\"\n",
      "  },\n",
      "  \"tags\": {},\n",
      "  \"type\": \"managed\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All traffic will be set to deployment blue once it has been provisioned.\n",
      "If you interrupt this command or it times out while waiting for the provisioning, you can try to set all the traffic to this deployment later once its has been provisioned.\n",
      "Check: endpoint finetunedPhi3Endpoint exists\n"
     ]
    }
   ],
   "source": [
    "!az ml online-deployment create --all-traffic --file ./endpoint/deployment.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "many_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
